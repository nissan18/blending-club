{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "1. accuracy CANNOT be 100% (even for SVM??)\n",
    "1. study why different dataSets have different hellpers.getFeatures()\n",
    "1. scikit classifier batch predict?\n",
    "1. study performance of models\n",
    "1. remove bad features (e.g. id)\n",
    "1. add remaining good features\n",
    "1. model and train regression models predicting actual return rate\n",
    "1. thinks how to continuously train models (every month, or something like that), productionize?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "# import columns\n",
    "import definitions\n",
    "import pandas_helper\n",
    "import lendingclub_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2007-2011': '../data/LoanStats3a_securev1.csv', '2012-2013': '../data/LoanStats3b_securev1.csv', '2014': '../data/LoanStats3c_securev1.csv', '2015': '../data/LoanStats3d_securev1.csv', '2016Q1': '../data/LoanStats_securev1_2016Q1.csv', '2016Q2': '../data/LoanStats_securev1_2016Q2.csv', '2016Q3': '../data/LoanStats_securev1_2016Q3.csv', '2016Q4': '../data/LoanStats_securev1_2016Q4.csv', '2017Q1': '../data/LoanStats_securev1_2017Q1.csv', '2017Q2': '../data/LoanStats_securev1_2017Q2.csv', '2017Q3': '../data/LoanStats_securev1_2017Q3.csv', '2017Q4': '../data/LoanStats_securev1_2017Q4.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(definitions.dataFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 2007-2011\n",
      "Loading data for 2012-2013\n",
      "Loading data for 2014\n",
      "Loading data for 2015\n",
      "Loading data for 2016Q1\n",
      "Loading data for 2016Q2\n",
      "Loading data for 2016Q3\n",
      "Loading data for 2016Q4\n",
      "Loading data for 2017Q1\n",
      "Loading data for 2017Q2\n",
      "Loading data for 2017Q3\n",
      "Loading data for 2017Q4\n"
     ]
    }
   ],
   "source": [
    "dataFrames = {}\n",
    "for key in definitions.dataFiles:\n",
    "    print(\"Loading data for \" + key)\n",
    "    dataFrames[key] = pandas_helper.readData(definitions.dataFiles[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building features for 2007-2011\n",
      "Building features for 2012-2013\n",
      "Building features for 2014\n",
      "Building features for 2015\n",
      "Building features for 2016Q1\n",
      "Building features for 2016Q2\n",
      "Building features for 2016Q3\n",
      "Building features for 2016Q4\n",
      "Building features for 2017Q1\n",
      "Building features for 2017Q2\n",
      "Building features for 2017Q3\n",
      "Building features for 2017Q4\n"
     ]
    }
   ],
   "source": [
    "for key in dataFrames.keys():\n",
    "    print(\"Building features for \" + key)\n",
    "    lendingclub_helper.buildFeatures(dataFrames[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-2011\n",
      "2012-2013\n",
      "2014\n",
      "2015\n",
      "2016Q1\n",
      "2016Q2\n",
      "2016Q3\n",
      "2016Q4\n",
      "2017Q1\n",
      "2017Q2\n",
      "2017Q3\n",
      "2017Q4\n"
     ]
    }
   ],
   "source": [
    "featureColumns = None\n",
    "for key in dataFrames.keys():\n",
    "    print(key)\n",
    "    if featureColumns is None:\n",
    "        featureColumns = [c for c in dataFrames[key].columns if c.startswith(\"f_\")]\n",
    "    elif set(featureColumns) != set([c for c in dataFrames[key].columns if c.startswith(\"f_\")]):\n",
    "        print(key + \": has different features\")\n",
    "# featureColumns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-2011\n",
      "2007-2011 has NULL columns\n",
      "2012-2013\n",
      "2012-2013 has NULL columns\n",
      "2014\n",
      "2014 has NULL columns\n",
      "2015\n",
      "2015 has NULL columns\n",
      "2016Q1\n",
      "2016Q1 has NULL columns\n",
      "2016Q2\n",
      "2016Q2 has NULL columns\n",
      "2016Q3\n",
      "2016Q3 has NULL columns\n",
      "2016Q4\n",
      "2016Q4 has NULL columns\n",
      "2017Q1\n",
      "2017Q1 has NULL columns\n",
      "2017Q2\n",
      "2017Q2 has NULL columns\n",
      "2017Q3\n",
      "2017Q3 has NULL columns\n",
      "2017Q4\n",
      "2017Q4 has NULL columns\n"
     ]
    }
   ],
   "source": [
    "for key in dataFrames.keys():\n",
    "    print(key)\n",
    "    if pandas_helper.columnsHaveNull(dataFrames[key], featureColumns):\n",
    "        print(key + \" has NULL columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-2011\n",
      "2012-2013\n",
      "2014\n",
      "2015\n",
      "2016Q1\n",
      "2016Q2\n",
      "2016Q3\n",
      "2016Q4\n",
      "2017Q1\n",
      "2017Q2\n",
      "2017Q3\n",
      "2017Q4\n"
     ]
    }
   ],
   "source": [
    "for key in dataFrames.keys():\n",
    "    print(key)\n",
    "    for c in featureColumns:\n",
    "        if pandas_helper.columnHasNull(dataFrames[key], c):\n",
    "            print(c + \" has NULL values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAllNotNull(column):\n",
    "    print(\"Checking: \" + column)\n",
    "    found = False\n",
    "    for key in dataFrames:\n",
    "        if dataFrames[key][column].isnull().any():\n",
    "            print(\"Found null data in \" + key)\n",
    "            found = True\n",
    "    if not found:\n",
    "        print(\"No null data found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describeAll(column):\n",
    "    for key in dataFrames:\n",
    "        print(\"Describing \" + key)\n",
    "        print(dataFrames[key][column].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createColumn(column, fromColumn, parseFunction):\n",
    "    print(\"Creating: \" + column)\n",
    "    for key in dataFrames:\n",
    "        print(\"Processing: \" + key)\n",
    "        dataFrames[key][column] = dataFrames[key][fromColumn].apply(parseFunction)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: f_acc_now_delinq\n",
      "No null data found\n"
     ]
    }
   ],
   "source": [
    "# df1[\"f_acc_now_delinq\"].isnull().any()\n",
    "# createColumn(\"f_acc_now_delinq\", \"acc_now_delinq\", columns.parse_acc_now_delinq)\n",
    "checkAllNotNull(\"f_acc_now_delinq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file1: ../data/LoanStats3a_securev1.csv\n",
      "file2: ../data/LoanStats_securev1_2017Q1.csv\n"
     ]
    }
   ],
   "source": [
    "file1 = definitions.dataFiles[\"2007-2011\"]\n",
    "print(\"file1: \" + file1)\n",
    "file2 = definitions.dataFiles[\"2017Q1\"]\n",
    "print(\"file2: \" + file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1.shape: (42535, 151)\n",
      "len(df1_features): 22\n",
      "df1_trimmed.shape: (42535, 151)\n",
      "len(df1_trimmed_features): 22\n",
      "df2.shape: (96779, 151)\n",
      "len(df2_features): 71\n",
      "df2_trimmed.shape: (19286, 151)\n",
      "len(df2_trimmed_features): 72\n"
     ]
    }
   ],
   "source": [
    "df1 = pandas.read_csv(file1, dtype=columns.dtypes)\n",
    "print(\"df1.shape: {0}\".format(df1.shape))\n",
    "df1_features = helpers.getFeatures(df1)\n",
    "print(\"len(df1_features): {0}\".format(len(df1_features)))\n",
    "\n",
    "df1_trimmed = helpers.getFinishedLoans(df1)\n",
    "print(\"df1_trimmed.shape: {0}\".format(df1_trimmed.shape))\n",
    "df1_trimmed_features = helpers.getFeatures(df1_trimmed)\n",
    "print(\"len(df1_trimmed_features): {0}\".format(len(df1_trimmed_features)))\n",
    "\n",
    "df2 = pandas.read_csv(file2, dtype=columns.dtypes)\n",
    "print(\"df2.shape: {0}\".format(df2.shape))\n",
    "df2_features = helpers.getFeatures(df2)\n",
    "print(\"len(df2_features): {0}\".format(len(df2_features)))\n",
    "\n",
    "df2_trimmed = helpers.getFinishedLoans(df2)\n",
    "print(\"df2_trimmed.shape: {0}\".format(df2_trimmed.shape))\n",
    "df2_trimmed_features = helpers.getFeatures(df2_trimmed)\n",
    "print(\"len(df2_trimmed_features): {0}\".format(len(df2_trimmed_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: earliest_cr_line\n",
      "Found null data in 2007-2011\n",
      "Describing 2007-2011\n",
      "count        42506\n",
      "unique         530\n",
      "top       Oct-1999\n",
      "freq           393\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2012-2013\n",
      "count       188181\n",
      "unique         614\n",
      "top       Oct-2000\n",
      "freq          1646\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2014\n",
      "count       235629\n",
      "unique         638\n",
      "top       Aug-2001\n",
      "freq          1980\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2015\n",
      "count       421095\n",
      "unique         668\n",
      "top       Aug-2002\n",
      "freq          3235\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2016Q1\n",
      "count       133887\n",
      "unique         633\n",
      "top       Aug-2003\n",
      "freq           975\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2016Q2\n",
      "count        97854\n",
      "unique         612\n",
      "top       Sep-2003\n",
      "freq           755\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2016Q3\n",
      "count        99120\n",
      "unique         614\n",
      "top       Aug-2003\n",
      "freq           796\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2016Q4\n",
      "count       103546\n",
      "unique         621\n",
      "top       Sep-2003\n",
      "freq           788\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2017Q1\n",
      "count        96779\n",
      "unique         620\n",
      "top       Sep-2004\n",
      "freq           767\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2017Q2\n",
      "count       105451\n",
      "unique         627\n",
      "top       Sep-2004\n",
      "freq           892\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2017Q3\n",
      "count       122701\n",
      "unique         631\n",
      "top       Sep-2005\n",
      "freq          1020\n",
      "Name: earliest_cr_line, dtype: object\n",
      "Describing 2017Q4\n",
      "count       118648\n",
      "unique         639\n",
      "top       Sep-2005\n",
      "freq          1015\n",
      "Name: earliest_cr_line, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# set(df1_trimmed_features) - set(df2_trimmed_features)\n",
    "# df2[\"dti\"].isnull().any()\n",
    "col = \"earliest_cr_line\"  # bc_util\n",
    "checkAllNotNull(col)\n",
    "describeAll(col)\n",
    "\n",
    "# for key in definitions.dataFiles:\n",
    "#     print(key)\n",
    "#     print(dataFrames[key][col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42535\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# print(df1[col].describe())\n",
    "print(df1[col].isnull().count())\n",
    "# print(df2[col].describe())\n",
    "print(df2[col].isnull().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df2_trimmed_features) - set(df1_trimmed_features)\n",
    "# df1[\"acc_now_delinq\"].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"f_acc_now_delinq\"] = df1[\"acc_now_delinq\"].apply(columns.parse_acc_now_delinq)\n",
    "df1[\"acc_now_delinq\"].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'sooka'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ce9f1fc00519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sooka\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'sooka'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
